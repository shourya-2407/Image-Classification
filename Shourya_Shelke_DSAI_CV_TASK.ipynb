{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shourya_Shelke_DSAI-CV-TASK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shourya-2407/Image-Classification/blob/master/Shourya_Shelke_DSAI_CV_TASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy3H3J6TUC5Z",
        "colab_type": "text"
      },
      "source": [
        "## COMPUTER VISION TASK - DSAI INDUCTIONS 2020 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rXJn7C2SfK_",
        "colab_type": "text"
      },
      "source": [
        "This Notebook contains starter code for the Computer Vision Task for DSAI Inductions. We have used PyTorch here, but you are free to use any relevant Deep Learning framework like TensorFlow,Trax; However PyTorch is now like the international research standard for Deep Learning, so using PyTorch for the task would be appreciated.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoj8rfF1UPNu",
        "colab_type": "text"
      },
      "source": [
        "The task involves classification of images on the SVHN classification dataset.\n",
        "SVHN stands for Street View House Numbers. Similar to MNIST, SVHN classification is a digit recognition task. Answer classes range from 0 to 9.\n",
        "You should prepare a model and report test set accuracy and submit the following to us for evaluation:\n",
        "\n",
        "For PyTorch Users:\n",
        "1. model.pt file  \n",
        "2. model.py file\n",
        "3. link to Colab notebook\n",
        "\n",
        "For Tensorflow Users:\n",
        "1. .h5 file of model and weights\n",
        "2. link to Colab notebook\n",
        "\n",
        "The colab notebook should have proper comments describing the code.\n",
        "\n",
        "Note: There are 2 variants of SVHN available on the internet. One involving Bounding Box Detection + Classification and the second involving only classification. We are only concerned with the latter (i.e. Classification only dataset). It is also refered to as svhn_cropped in alternate texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1-mmIjCSOTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "\n",
        "# Necessary Imports to run this starter code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBuQz0qlnQ8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                    \n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#Transforms to convert Image --> Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piNvp6iPnRib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2a51dcd5-5b8a-4bee-95ce-8dfcf8440516"
      },
      "source": [
        "trainset  = torchvision.datasets.SVHN('./data', split='train',download=True,transform=transform)\n",
        "testset =  torchvision.datasets.SVHN('./data', split='test',download=True,transform=transform)\n",
        "\n",
        "# Download Train and Test Dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKofjc_6nav_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=testset,\n",
        "                                              batch_size=64,\n",
        "                                              shuffle=True,\n",
        "                                              )\n",
        "test_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                              batch_size=64,\n",
        "                                              shuffle=True,\n",
        "                                              )\n",
        "# Set up the dataloaders to be used in training and testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E4LzN11pFfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e81f0a20-2935-4e09-e2f1-9d545f221499"
      },
      "source": [
        "# Optional Code just for visualization\n",
        "\n",
        "image_ind = 98  # Any index you want to visualize\n",
        "train_data = sio.loadmat('./data/train_32x32.mat')\n",
        "\n",
        "# access to the dict\n",
        "x_train = train_data['X']\n",
        "y_train = train_data['y']\n",
        "\n",
        "# show sample\n",
        "plt.imshow(x_train[:,:,:,image_ind])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Label : \", y_train[image_ind].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label :  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBXvQFPVcRFT",
        "colab_type": "text"
      },
      "source": [
        "#**USING KERAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixnvuk6AMzSW",
        "colab_type": "text"
      },
      "source": [
        "##**Important Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gcPs9nQTjnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adadelta, Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.io import loadmat\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import  TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuO3KOzaTjgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = 'SVHN_CNN-{}'.format(int(time.time()))\n",
        "tensorboard = TensorBoard(log_dir='drive/My Drive/Colab Notebooks/logs/{}'.format(NAME))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZdLFOqHTjY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0b746e35-9fe1-4535-dea4-2b55970ff392"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-PUlNFXZ7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4df93024-69df-48ca-ddf7-0c4c1761413e"
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xkygmb_XgQV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Data Processing\n",
        "#Uploading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy1h2Y6jXZ3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = loadmat('drive/My Drive/Colab Notebooks/train_32x32.mat')\n",
        "test_data = loadmat ('drive/My Drive/Colab Notebooks/test_32x32.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ralmhCGMch-r",
        "colab_type": "text"
      },
      "source": [
        "##**Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYM18k46XZ1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train and test data into X and y\n",
        "X_train, y_train = train_data['X'], train_data['y']\n",
        "X_test, y_test = test_data['X'], test_data['y']\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKtPFGXecqCR",
        "colab_type": "text"
      },
      "source": [
        "###**Transposing the image arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7er7S9GvXZyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = X_train.transpose((3,0,1,2)), y_train[:,0]\n",
        "X_test, y_test = X_test.transpose((3,0,1,2)), y_test[:,0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsIlWTdaXZwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting class \"10\" to class \"0\"\n",
        "y_train[y_train == 10] = 0\n",
        "y_test[y_test == 10] = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8m2NP-Ec6VK",
        "colab_type": "text"
      },
      "source": [
        "##**Training Dataset Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94vxw4mXZtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjvFJOg-XZqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split (X_train, y_train, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20X6QrHydB5H",
        "colab_type": "text"
      },
      "source": [
        "##**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98z49LwmL5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvq7ARFTXZpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First Layer\n",
        "model.add(Convolution2D(32, [3, 3], input_shape=(32, 32, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Second Layer\n",
        "model.add(Convolution2D(32, [3, 3]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Third Layer\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(64, [3, 3], padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Fourth Layer\n",
        "model.add(Convolution2D(64, [3, 3]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Fifth Layer\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIllL2aIXZlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "514dfc23-8b57-415f-81eb-f3775e0730a5"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data= (X_val, y_val), batch_size = 128, epochs= 10, verbose= 1, callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "458/458 [==============================] - 5s 12ms/step - loss: 0.8724 - accuracy: 0.7254 - val_loss: 0.4378 - val_accuracy: 0.8696\n",
            "Epoch 2/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.4541 - accuracy: 0.8611 - val_loss: 0.3400 - val_accuracy: 0.8984\n",
            "Epoch 3/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.3866 - accuracy: 0.8824 - val_loss: 0.3111 - val_accuracy: 0.9070\n",
            "Epoch 4/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.3466 - accuracy: 0.8936 - val_loss: 0.2808 - val_accuracy: 0.9191\n",
            "Epoch 5/10\n",
            "458/458 [==============================] - 5s 11ms/step - loss: 0.3143 - accuracy: 0.9043 - val_loss: 0.2721 - val_accuracy: 0.9212\n",
            "Epoch 6/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.2884 - accuracy: 0.9135 - val_loss: 0.3424 - val_accuracy: 0.8952\n",
            "Epoch 7/10\n",
            "458/458 [==============================] - 5s 11ms/step - loss: 0.2757 - accuracy: 0.9163 - val_loss: 0.2462 - val_accuracy: 0.9309\n",
            "Epoch 8/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.2566 - accuracy: 0.9221 - val_loss: 0.2489 - val_accuracy: 0.9300\n",
            "Epoch 9/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.2408 - accuracy: 0.9274 - val_loss: 0.2354 - val_accuracy: 0.9337\n",
            "Epoch 10/10\n",
            "458/458 [==============================] - 5s 10ms/step - loss: 0.2266 - accuracy: 0.9315 - val_loss: 0.2336 - val_accuracy: 0.9329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f5fee42b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI411mKodR81",
        "colab_type": "text"
      },
      "source": [
        "##**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBR43uowYEHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzrfEpKNYD_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f76ac723-3c58-4ffc-ee8e-75f6901abfef"
      },
      "source": [
        "val_loss, val_acc = model.evaluate (X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "814/814 [==============================] - 3s 3ms/step - loss: 0.2540 - accuracy: 0.9276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_Xjd-aYD38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31390752-a345-46b5-b832-365d0777b8c2"
      },
      "source": [
        "print(val_loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.25397789478302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvY_bWaMYTgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b3df14-c6a2-46ac-c691-08aff3913396"
      },
      "source": [
        "print(val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9276275634765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4J6cdgkYfw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPhkMYylZro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5707f5f-100d-4924-e44a-0ff09c19b9b3"
      },
      "source": [
        "!ls saved_model/my_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_AGF1wVsDTp",
        "colab_type": "text"
      },
      "source": [
        "#Click on the share button in the top right corner of this notebook, copy the link and send it to us along with the other files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpMor1z7s_1D",
        "colab_type": "text"
      },
      "source": [
        "Refer to [this](https://colab.research.google.com/drive/1OYAbJ_t8ZAIjy4aT_mFgPGkhRPB2X5Iy?usp=sharing) notebook for a complete working example of Image Classification on MNIST.\n",
        "Save a copy in your google drive account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWvJkPpBti0a",
        "colab_type": "text"
      },
      "source": [
        "For Tensorflow(Keras) users, refer to this [link](https://www.tensorflow.org/guide/keras/save_and_serialize) for saving the .h5 file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCDP54Matvo4",
        "colab_type": "text"
      },
      "source": [
        "Hints to solve the task:\n",
        "1. Refer to the DSAI Session 1 recording [here](https://web.microsoftstream.com/video/9616fbd1-f2ec-4c7f-82d3-c8192719d482)\n",
        "2. CNNs work very well for Image Classification tasks\n",
        "3. CNNs are data hungry, more the data better the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L5ed7eu9O1B",
        "colab_type": "text"
      },
      "source": [
        "For any questions related to the task, Contact :\n",
        "1. Shaunak Halbe\n",
        "2. Ph : 7588170950 (Whatsapp No.)\n",
        "3. E-mail: halbesa18.comp@coep.ac.in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mx9YNZ69dn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}